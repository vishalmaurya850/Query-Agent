{
    "_descriptorVersion": "0.0.1",  
    "datePublished": "2024-02-21T16:54:57.000Z",
    "name": "Google's Gemma 2B Instruct",
    "description": "Gemma is a family of lightweight LLMs built from the same research and technology Google used to create the Gemini models. Gemma models are available in two sizes, 2 billion and 7 billion parameters. These models are trained on up to 6T tokens of primarily English web documents, mathematics, and code, using a transformer architecture with enhancements like Multi-Query Attention, RoPE Embeddings, GeGLU Activations, and advanced normalization techniques.",
    "author": {
      "name": "Google DeepMind",
      "url": "https://deepmind.google",
      "blurb": "Weâ€™re a team of scientists, engineers, ethicists and more, working to build the next generation of AI systems safely and responsibly."
    },
    "numParameters": "2B",
    "resources": {
      "canonicalUrl": "https://huggingface.co/google/gemma-2b-it",
      "paperUrl": "https://blog.google/technology/developers/gemma-open-models/",
      "downloadUrl": "https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF"
    },
    "trainedFor": "chat",
    "arch": "gemma",
    "files": {
      "highlighted": {
        "economical": {
          "name": "gemma-2b-it-q8_0.gguf"
        }
      },
      "all": [
        {
          "name": "gemma-2b-it-q8_0.gguf",
          "url": "https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF/resolve/main/gemma-2b-it-q8_0.gguf",
          "sizeBytes": 2669351840,
          "quantization": "Q8_0",
          "format": "gguf",
          "sha256checksum": "ec68b50d23469882716782da8b680402246356c3f984e9a3b9bcc5bc15273140",
          "publisher": {
            "name": "LM Studio",
            "socialUrl": "https://twitter.com/LMStudioAI"
          },
          "respository": "lmstudio-ai/gemma-2b-it-GGUF",
          "repositoryUrl": "https://huggingface.co/lmstudio-ai/gemma-2b-it-GGUF"
        }
      ]
    }
  }
